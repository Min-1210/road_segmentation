import os
import time
import torch
import yaml
import segmentation_models_pytorch as smp
from tqdm import tqdm

from utils import set_seed, get_model, get_loss_function, get_optimizer, get_scheduler, pixel_accuracy
from dataset import get_dataloaders
from plot import save_training_plots

def main(config_path='config.yaml'):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    set_seed(config['seed'])
    device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))
    os.makedirs(config['training']['plot_dir'], exist_ok=True)

    print("üîÑ T·∫£i d·ªØ li·ªáu...")
    train_loader, val_loader = get_dataloaders(config)

    print("üîß Kh·ªüi t·∫°o m√¥ h√¨nh, h√†m loss, v√† optimizer...")
    model = get_model(config).to(device)
    loss_fn = get_loss_function(config)
    optimizer = get_optimizer(model, config)
    scheduler = get_scheduler(optimizer, config)

    print(f"M√¥ h√¨nh: {config['model']['name']} ({config['model']['encoder_name']})")
    print(f"H√†m loss: {config['loss']['name']}")
    num_classes = config['model']['classes']
    print(f"S·ªë l·ªõp: {num_classes}")
    print(f"Hu·∫•n luy·ªán tr√™n thi·∫øt b·ªã: {device}")

    loss_mode = "binary" if num_classes == 1 else "multiclass"

    metrics_to_track = {
        "iou_score": smp.metrics.iou_score,
        "f1_score": smp.metrics.f1_score,
        "accuracy": pixel_accuracy,
        "dice_loss": smp.losses.DiceLoss(mode=loss_mode),
        "jaccard_loss": smp.losses.JaccardLoss(mode=loss_mode),
        "focal_loss": smp.losses.FocalLoss(mode=loss_mode),
    }
    if num_classes == 1:
        metrics_to_track["bce_loss"] = torch.nn.BCEWithLogitsLoss()

    history = {"train_loss": [], "val_loss": []}
    for name in metrics_to_track:
        history[f"train_{name}"] = []
        history[f"val_{name}"] = []

    start_time = time.time()
    print("\n--- B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán ---")

    for epoch in range(config['training']['num_epochs']):
        epoch_start = time.time()

        # Hu·∫•n luy·ªán
        model.train()
        running_train_loss = 0.0
        for images, masks in tqdm(train_loader, desc=f"Epoch {epoch + 1} Train"):
            images, masks = images.to(device), masks.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_fn(outputs, masks)
            loss.backward()
            optimizer.step()
            running_train_loss += loss.item()
        history["train_loss"].append(running_train_loss / len(train_loader))

        # Validation
        model.eval()
        running_val_loss = 0.0
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                loss = loss_fn(outputs, masks)
                running_val_loss += loss.item()
        history["val_loss"].append(running_val_loss / len(val_loader))

        # ƒê√°nh gi√° metric
        for phase in ['train', 'val']:
            loader = train_loader if phase == 'train' else val_loader
            total_tp, total_fp, total_fn, total_tn = None, None, None, None
            metric_sums = {name: 0.0 for name in metrics_to_track}

            with torch.no_grad():
                for images, masks in loader:
                    images, masks = images.to(device), masks.to(device)
                    outputs = model(images)

                    if num_classes == 1:
                        pred_masks = (torch.sigmoid(outputs) > 0.5).long()
                        tp, fp, fn, tn = smp.metrics.get_stats(pred_masks, masks.long(), mode='binary')
                        tp, fp, fn, tn = tp.sum(), fp.sum(), fn.sum(), tn.sum()

                    else:
                        pred_masks = torch.argmax(outputs, dim=1)
                        tp, fp, fn, tn = smp.metrics.get_stats(pred_masks, masks.long(), mode='multiclass',
                                                               num_classes=num_classes)

                        tp, fp, fn, tn = tp.sum(dim=0), fp.sum(dim=0), fn.sum(dim=0), tn.sum(dim=0)

                    if total_tp is None:
                        total_tp, total_fp, total_fn, total_tn = tp, fp, fn, tn
                    else:
                        total_tp += tp
                        total_fp += fp
                        total_fn += fn
                        total_tn += tn

                    for name, func in metrics_to_track.items():
                        if name in ["iou_score", "f1_score"]:
                            score_tensor = func(total_tp, total_fp, total_fn, total_tn)
                            if score_tensor.numel() == 1:
                                metric_sums[name] += score_tensor.item()
                            else:
                                metric_sums[name] += score_tensor.mean().item()
                        elif name == "accuracy":
                            metric_sums[name] += func(outputs, masks)
                        elif "loss" in name:
                            metric_sums[name] += func(outputs, masks).item()

            for name in metrics_to_track:
                history[f"{phase}_{name}"].append(metric_sums[name] / len(loader))

        scheduler.step(history["val_loss"][-1])

        epoch_time = time.time() - epoch_start
        print(f"Epoch {epoch + 1:02d}/{config['training']['num_epochs']} | Train Loss: {history['train_loss'][-1]:.4f} | Val Loss: {history['val_loss'][-1]:.4f} | Val IoU: {history['val_iou_score'][-1]:.4f} | Val F1: {history['val_f1_score'][-1]:.4f} | üïí {epoch_time:.2f}s")

    end_time = time.time()
    print("\n--- Hu·∫•n luy·ªán ho√†n t·∫•t ---")
    print(f"‚è±Ô∏è T·ªïng th·ªùi gian hu·∫•n luy·ªán: {(end_time - start_time) / 60:.2f} ph√∫t")

    torch.save(model.state_dict(), config['training']['model_path'])
    print(f"‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {config['training']['model_path']}")

    save_training_plots(history, config)


if __name__ == '__main__':
    main()
